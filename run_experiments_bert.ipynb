{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>>> cuda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/14/2022 19:48:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\transformers\\data\\processors\\glue.py:284: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\connection.py\", line 174, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\socket.py\", line 918, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1010, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\connection.py\", line 358, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\connection.py\", line 186, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x000001B120749340>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\urllib3\\util\\retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/bert-base-cased (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B120749340>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \".\\examples\\run_glue.py\", line 702, in <module>\n",
      "    main()\n",
      "  File \".\\examples\\run_glue.py\", line 561, in main\n",
      "    tokenizer = tokenizer_class.from_pretrained(args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1651, in from_pretrained\n",
      "    fast_tokenizer_file = get_fast_tokenizer_file(\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 3467, in get_fast_tokenizer_file\n",
      "    all_files = get_list_of_files(\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\transformers\\file_utils.py\", line 1818, in get_list_of_files\n",
      "    model_info = HfApi(endpoint=HUGGINGFACE_CO_RESOLVE_ENDPOINT).model_info(\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\huggingface_hub\\hf_api.py\", line 584, in model_info\n",
      "    r = requests.get(path, headers=headers, timeout=timeout)\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\requests\\api.py\", line 75, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\requests\\api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\requests\\sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\requests\\sessions.py\", line 655, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\Windows\\Anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\requests\\adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/bert-base-cased (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001B120749340>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    }
   ],
   "source": [
    "!python .\\examples\\run_glue.py --overwrite_output_dir --model_type bert --model_name_or_path bert-base-cased --task_name CoLA --do_train --do_eval --do_lower_case --data_dir ./../glue_data/CoLA  --max_seq_length 128 --per_gpu_train_batch_size 16 --learning_rate 2e-5  --num_train_epochs 15 --output_dir ./../bert_cola/ --save_steps 0 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\examples\\run_glue.py --overwrite_output_dir --model_type bert --model_name_or_path bert-base-cased --task_name SST-2 --do_train --do_eval --do_lower_case --data_dir ./../glue_data/SST-2  --max_seq_length 128 --per_gpu_train_batch_size 16 --learning_rate 2e-5  --num_train_epochs 15 --output_dir ./../bert_sst2/ --save_steps 0 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\examples\\run_glue.py --overwrite_output_dir --model_type bert --model_name_or_path bert-base-cased --task_name MRPC --do_train --do_eval --do_lower_case --data_dir ./../glue_data/MRPC  --max_seq_length 128 --per_gpu_train_batch_size 16 --learning_rate 2e-5  --num_train_epochs 15 --output_dir ./../bert_mrpc/ --save_steps 0 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\examples\\run_glue.py --overwrite_output_dir --model_type bert --model_name_or_path bert-base-cased --task_name QNLI --do_train --do_eval --do_lower_case --data_dir ./../glue_data/QNLI  --max_seq_length 128 --per_gpu_train_batch_size 16 --learning_rate 2e-5  --num_train_epochs 15 --output_dir ./../bert_qnli/ --save_steps 0 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\examples\\run_glue.py --overwrite_output_dir --model_type bert --model_name_or_path bert-base-cased --task_name QQP --do_train --do_eval --do_lower_case --data_dir ./../glue_data/QQP  --max_seq_length 128 --per_gpu_train_batch_size 16 --learning_rate 2e-5  --num_train_epochs 15 --output_dir ./../bert_qqp/ --save_steps 0 --evaluate_during_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\examples\\run_glue.py --overwrite_output_dir --model_type bert --model_name_or_path bert-base-cased --task_name RTE --do_train --do_eval --do_lower_case --data_dir ./../glue_data/RTE  --max_seq_length 128 --per_gpu_train_batch_size 16 --learning_rate 2e-5  --num_train_epochs 15 --output_dir ./../bert_rte/ --save_steps 0 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\examples\\run_glue.py --overwrite_output_dir --model_type bert --model_name_or_path bert-base-cased --task_name WNLI --do_train --do_eval --do_lower_case --data_dir ./../glue_data/WNLI  --max_seq_length 128 --per_gpu_train_batch_size 16 --learning_rate 2e-5  --num_train_epochs 15 --output_dir ./../bert_wnli/ --save_steps 0 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python .\\examples\\run_glue.py --overwrite_output_dir --model_type bert --model_name_or_path bert-base-cased --task_name MNLI --do_train --do_eval --do_lower_case --data_dir ./../glue_data/MNLI  --max_seq_length 128 --per_gpu_train_batch_size 16 --learning_rate 2e-5  --num_train_epochs 15 --output_dir ./../bert_mnli/ --save_steps 0 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4224a284912126f805ae0ee160b4a432bf2336f134b0772df0c6ad7ad36981c3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
